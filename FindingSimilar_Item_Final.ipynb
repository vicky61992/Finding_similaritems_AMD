{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgIrXdIUSzS",
        "outputId": "c4a434cc-d1b1-40aa-93c3-cddaaeea16c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=54d3384809fa03357714bde5ffcbb2669c20510ab05262a832869c93e7551948\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFXC_4fsT2v4",
        "outputId": "906351da-a857-49f4-9621-eab80abc7f1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Importing Labraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pyspark\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import ArrayType, StringType, FloatType,IntegerType\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "from pyspark.sql.functions import lower\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Data Download\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "dMt6YJnPUMIa",
        "outputId": "ab8817a0-76c2-45a0-9cd8-d1d7c9bd73be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6024b872-55bb-4fd7-8209-7999ef3c9db1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6024b872-55bb-4fd7-8209-7999ef3c9db1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 72 bytes\n"
          ]
        }
      ],
      "source": [
        "# Using Kaggle API to Download the Dataset\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnlGqTzHUtPf",
        "outputId": "62aefe00-9445-4885-96e2-84cf5d2b8fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 1-3m-linkedin-jobs-and-skills-2024.zip to /content\n",
            "100% 1.88G/1.88G [00:46<00:00, 43.5MB/s]\n",
            "100% 1.88G/1.88G [00:46<00:00, 43.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the Dataset\n",
        "!kaggle datasets download -d asaniczka/1-3m-linkedin-jobs-and-skills-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIH8qq36U9Hb",
        "outputId": "d3105a51-d099-4471-bb7d-8594b247fff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Unzip and extracting data into content folder\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/1-3m-linkedin-jobs-and-skills-2024.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "  zip.extractall(path=\"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9QEBJQ7hU_bw"
      },
      "outputs": [],
      "source": [
        "# create spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"similaritems\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zC9DiaV9VGcj"
      },
      "outputs": [],
      "source": [
        "# Creating Dataframe\n",
        "df = spark.read \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", \"true\")\\\n",
        "    .load(\"/content/job_summary.csv\").select('job_summary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpPcDxBYVlow",
        "outputId": "f2ade0ca-0c78-4c23-de46-a440972da889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48219735\n"
          ]
        }
      ],
      "source": [
        "# Counting number of rows\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AGEo15S3VIVQ"
      },
      "outputs": [],
      "source": [
        "# Drop rows with null values in either of the columns\n",
        "df_dropna = df.select(\"job_summary\")\n",
        "df_dropna = df_dropna.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngFexmyWyJq",
        "outputId": "3fb70307-273e-42bc-c2a7-d47c34f266e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15572837\n"
          ]
        }
      ],
      "source": [
        "# Counting number of rows after removing NaN\n",
        "print(df_dropna.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QOo4QrQXWP7D"
      },
      "outputs": [],
      "source": [
        "# Define a UDF to count sentences using NLTK\n",
        "def count_sentences(text):\n",
        "    return len(nltk.sent_tokenize(text)) if text else 0\n",
        "\n",
        "count_sentences_udf = udf(count_sentences, IntegerType())\n",
        "# Add a new column with sentence count\n",
        "df_filtered = df_dropna.withColumn(\"sentence_count\", count_sentences_udf(\"job_summary\"))\n",
        "\n",
        "\n",
        "# Filter rows with more than sentence count more then 10 sentence and only 500rows\n",
        "df_filtered = df_filtered.filter(col(\"sentence_count\") > 10)\n",
        "df_filtered = df_filtered.limit(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "srIFnkikXhZU"
      },
      "outputs": [],
      "source": [
        "# Add an index column\n",
        "df_index = df_filtered.withColumn(\"Index\", monotonically_increasing_id() + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2RH10MGrbzKY"
      },
      "outputs": [],
      "source": [
        " # Creating lower case text column\n",
        "lower_df = df_index.withColumn(\"lower\", lower(df_index[\"job_summary\"]))\n",
        "\n",
        "# stopwords from NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define a UDF to remove stop words from a job_summary\n",
        "def stop_words_removal(job_summary):\n",
        "    words = job_summary.split()\n",
        "    stopwords = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(stopwords)\n",
        "\n",
        "# Register the UDF\n",
        "stop_words_removal_udf = udf(stop_words_removal, StringType())\n",
        "\n",
        "# Apply stop words removal UDF to the 'text' column\n",
        "filtered_df = lower_df.withColumn(\"filtered_text\", stop_words_removal_udf(\"lower\"))\n",
        "filtered_df = filtered_df.select(\"Index\",\"job_summary\",\"sentence_count\",\"lower\",\"filtered_text\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS_sfI4CgjSZ",
        "outputId": "4824d18c-d1e7-4f8e-dd83-0f5b13c3076b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------+--------------------+--------------------+\n",
            "|Index|         job_summary|sentence_count|               lower|       filtered_text|\n",
            "+-----+--------------------+--------------+--------------------+--------------------+\n",
            "|    1|Job Title: Senior...|            31|job title: senior...|job title: senior...|\n",
            "|    2|POSITION SUMMARYT...|            25|position summaryt...|position summaryt...|\n",
            "|    3|At Dominion Energ...|            11|at dominion energ...|dominion energy l...|\n",
            "|    4|Overview Discover...|            24|overview discover...|overview discover...|\n",
            "|    5|POSITION ELIGIBLE...|            13|position eligible...|position eligible...|\n",
            "|    6|CaroMont Health i...|            16|caromont health i...|caromont health h...|\n",
            "|    7|Hello, nurses! We...|            22|hello, nurses! we...|hello, nurses! re...|\n",
            "|    8|Hello, nurses! We...|            21|hello, nurses! we...|hello, nurses! re...|\n",
            "|    9|Overview Home Hea...|            11|overview home hea...|overview home hea...|\n",
            "|   10|\"Description****I...|            24|\"description****i...|\"description****i...|\n",
            "|   11|\"Description**In ...|            21|\"description**in ...|\"description**in ...|\n",
            "|   12|Overview Advanced...|            23|overview advanced...|overview advanced...|\n",
            "|   13|Job Summary:Manag...|            29|job summary:manag...|job summary:manag...|\n",
            "|   14|BE PART OF SOMETH...|            37|be part of someth...|part something mo...|\n",
            "|   15|Hello, nurses! We...|            22|hello, nurses! we...|hello, nurses! re...|\n",
            "|   16|R-00120212 Descri...|            24|r-00120212 descri...|r-00120212 descri...|\n",
            "|   17|\"Summary The Iowa...|            37|\"summary the iowa...|\"summary iowa cit...|\n",
            "|   18|\"If you enjoy wor...|            21|\"if you enjoy wor...|\"if enjoy working...|\n",
            "|   19|Position Title: C...|            49|position title: c...|position title: c...|\n",
            "|   20|\"Our Company**Gen...|            17|\"our company**gen...|\"our company**gen...|\n",
            "+-----+--------------------+--------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the result\n",
        "filtered_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qnL2VR_Kpgy",
        "outputId": "a535466d-9334-45cd-ec5c-aa04f1100451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, nurses! We are Reliance Home Health Caregivers! Immediate Hire $40.00 RN/ $ 33.00 LPN.We now need a SCHOOL NURSE to care for a 18-year-old male who lives in Country Club hills,IL 60478 covering Monday-Friday 6am-6pm.We are a home health care company that specializes in long-term 1-on-1 private duty nursing for disabled pediatric and adult patients on g-tubes, trachs, and vents. We have immediate openings for licensed nurses who want to truly make a difference in their patients' lives! We want to show you how a company that cares about their nurses and families can be! We have amazing schedulers who work hard to match the perfect nurse in specific cases with our precious children. We have amazing case managers and office staff that care about our employees. It is our mission that we strive to be the best pediatric nursing home health agency available. Nurses without pediatric experience will be considered. Training is available as well for pediatrics, home health and various skills. Please consider working with our wonderful company, and if you have worked for us in the past, please feel free to apply again! We have immediate openings in the following areas for reliable, compassionate Nurses: Chicagoland Area.We offer benefits package to our staff that includes: - Flexible hours/scheduling for Fulltime, Part time or PRN -8, 10, 12 or 16 hour shifts (employee's choice!)Differentials Skills Required: - Possess a valid LPN or RN license in the state of Illinois - Minimum of 1 year of direct patient care working as an RN / LPN/ CNA - Valid CPR cardJob Types: Full-time, Part-timeCOVID-19 considerations:PPE ARE AVAILABLEPM20Reliance Home Health Caregivers provides equal employment opportunities to all employees and applicants and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.I understand that neither the completion of this application nor any other part of my consideration for employment establishes any obligation for Reliance Home Health Caregivers to hire me. If I am hired, I understand that either Reliance Home Health Caregivers or I can terminate my employment at any time and for any reason, with or without cause and without prior notice. I understand that no representative of Reliance Home Health Caregivers has the authority to make any assurance to the contrary. I also understand that no guarantee will be given for the number of hours of work. Upon my termination, I authorize the release of reference information to potential employers.I understand that if an offer of employment is made, the following must be successfully completed as a condition of employment:A background check that will include: information from previous employers, whether contained in written records or not, all public/private records, including criminal, civil, driving, credit, and education, and any other pertinent information relating to my ability to successfully perform the job for which I have been offered employment.Pre-employment drug screening.Pre-employment physical.Proof of citizenship or authorization for employment in the United States is required in accordance with the Immigration Reform and Control Act of 1986. I attest that I have given to Reliance Home Health Caregivers true and complete information on this application. No requested information has been concealed. I authorize Reliance Home Health Caregivers to contact references provided for employment reference checks. If any information I have provided in untrue, or if I have concealed material information, I understand that this will constitute cause for the denial of employment or immediate dismissal.Powered by JazzHR\n"
          ]
        }
      ],
      "source": [
        "# for verifying the number of sentence\n",
        "print(df_filtered.select('job_summary').limit(10).collect()[7][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DhClo3N9o5_l"
      },
      "outputs": [],
      "source": [
        "# Function to generate shingles from text\n",
        "def generate_shingles(text, k=4):\n",
        "    tokens = text.split()\n",
        "    shingles = set()\n",
        "    for i in range(len(tokens) - k + 1):\n",
        "        shingle = \" \".join(tokens[i:i+k])\n",
        "        shingles.add(shingle)\n",
        "    return list(shingles)\n",
        "# Define a UDF for shingle generation\n",
        "generate_shingles_udf = F.udf(generate_shingles, ArrayType(StringType()))\n",
        "# Apply shingle generation UDF to filtertext\n",
        "shingled_df = filtered_df.withColumn(\"shingles\", generate_shingles_udf(col(\"filtered_text\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sNWunT6IOPxt"
      },
      "outputs": [],
      "source": [
        "# Define a function to calculate Jaccard similarity\n",
        "def jaccard_similarity(s1, s2):\n",
        "    set1 = set(s1)\n",
        "    set2 = set(s2)\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union != 0 else 0.0\n",
        "\n",
        "# Define a UDF for Jaccard similarity calculation\n",
        "jaccard_udf = udf(jaccard_similarity, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Qi4Z3drNo6DN"
      },
      "outputs": [],
      "source": [
        "# Cross join to create combinations\n",
        "cross_joined_df2 = shingled_df.crossJoin(shingled_df.withColumnRenamed(\"Index\", \"Index2\").withColumnRenamed(\"shingles\", \"shingles2\"))\n",
        "# Calculate Jaccard similarity for each pair of shingles\n",
        "jaccard_df1 = cross_joined_df2.withColumn(\"jaccard_similarity_onshingles\", jaccard_udf(col(\"shingles\"), col(\"shingles2\"))) \\\n",
        "                             .select(\"Index\", \"Index2\", \"jaccard_similarity_onshingles\")\n",
        "# Filter out rows where Index is not equal to Index2\n",
        "jaccard_df1 = jaccard_df1.filter(col(\"Index\") != col(\"Index2\"))\n",
        "jaccard_df1 = jaccard_df1.filter(col(\"jaccard_similarity_onshingles\") > 0.20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLmPNci1o6Xw",
        "outputId": "60810665-d7c4-4ad6-e095-287cb6b44262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+-----------------------------+\n",
            "|Index|Index2|jaccard_similarity_onshingles|\n",
            "+-----+------+-----------------------------+\n",
            "|    2|    32|                   0.94860816|\n",
            "|    7|     8|                    0.7690355|\n",
            "|    7|    15|                   0.77692306|\n",
            "|    8|     7|                    0.7690355|\n",
            "|    8|    15|                        0.872|\n",
            "|   10|    74|                   0.25268817|\n",
            "|   10|    82|                   0.28592163|\n",
            "|   10|   102|                   0.31753555|\n",
            "|   10|   167|                   0.30733946|\n",
            "|   10|   214|                     0.284127|\n",
            "|   10|   316|                    0.2976378|\n",
            "|   10|   338|                    0.3170347|\n",
            "|   10|   400|                   0.36983472|\n",
            "|   10|   425|                   0.30500758|\n",
            "|   10|   450|                    0.3013468|\n",
            "|   10|   459|                   0.32194245|\n",
            "|   10|   464|                   0.32545453|\n",
            "|   10|   470|                   0.32798573|\n",
            "|   12|    22|                    0.8290993|\n",
            "|   12|    36|                    0.6347518|\n",
            "+-----+------+-----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "jaccard_df1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5g5UHABco6bH"
      },
      "outputs": [],
      "source": [
        "# Function to compute MinHash signatures\n",
        "def minhash_signature(shingles, num_perm=128):\n",
        "    np.random.seed(42)\n",
        "    signature = np.inf * np.ones(num_perm, dtype=np.uint32)\n",
        "    for shingle in shingles:\n",
        "        hash_vals = np.array([hash(f\"{shingle}_{i}\") for i in range(num_perm)])\n",
        "        signature = np.minimum(signature, hash_vals)\n",
        "    return signature.tolist()\n",
        "\n",
        "# Define a UDF for MinHash signature generation\n",
        "minhash_signature_udf = udf(minhash_signature, ArrayType(StringType()))\n",
        "\n",
        "# Apply MinHash signature UDF to your DataFrame\n",
        "signature_df = shingled_df.withColumn(\"minhash_signature\", minhash_signature_udf(col(\"shingles\")))\n",
        "\n",
        "\n",
        "# Cross join to create combinations\n",
        "cross_joined_signature_df = signature_df.crossJoin(signature_df.withColumnRenamed(\"Index\", \"Index2\")\n",
        "                                                    .withColumnRenamed(\"minhash_signature\", \"minhash_signature2\"))\n",
        "\n",
        "# Calculate Jaccard similarity on signature matrix\n",
        "jaccard_signature_df = cross_joined_signature_df.withColumn(\"jaccard_similarity_signature\",\n",
        "                                                            jaccard_udf(col(\"minhash_signature\"),\n",
        "                                                                        col(\"minhash_signature2\"))) \\\n",
        "                                                                        .select(\"Index\", \"Index2\",\"jaccard_similarity_signature\")\n",
        "\n",
        "# Filter out rows where Index is not equal to Index2\n",
        "jaccard_signature_df = jaccard_signature_df.filter(col(\"Index\") != col(\"Index2\"))\n",
        "jaccard_signature_df = jaccard_signature_df.filter(col(\"jaccard_similarity_signature\") > 0.20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd4OqBB_AMdO",
        "outputId": "413815b1-671e-42ab-a944-3d695d9c4451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------------------------+\n",
            "|Index|Index2|jaccard_similarity_signature|\n",
            "+-----+------+----------------------------+\n",
            "|    2|    32|                    0.924812|\n",
            "|    7|     8|                   0.6516129|\n",
            "|    7|    15|                  0.68421054|\n",
            "|    8|     7|                   0.6516129|\n",
            "|    8|    15|                   0.7777778|\n",
            "|   10|   102|                  0.21904762|\n",
            "|   10|   167|                  0.21327014|\n",
            "|   10|   400|                  0.27363184|\n",
            "|   10|   425|                  0.23671497|\n",
            "|   10|   450|                  0.20754717|\n",
            "|   10|   459|                  0.22488038|\n",
            "|   10|   464|                  0.23671497|\n",
            "|   10|   470|                  0.24271844|\n",
            "|   12|    22|                  0.69536424|\n",
            "|   12|    36|                  0.52380955|\n",
            "|   13|    29|                   0.5802469|\n",
            "|   13|    35|                   0.9541985|\n",
            "|   13|    98|                   0.5802469|\n",
            "|   13|    99|                   0.9541985|\n",
            "|   15|     7|                  0.68421054|\n",
            "+-----+------+----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "jaccard_signature_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yryyq8eZb3e8",
        "outputId": "fea8c97b-c145-4180-a8c0-70d4edfc753e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "position summarythe registered nurse assesses patients, coordinates plan care, implements orders, evaluates nursing care provided oncology patients physician practice. nurse leads nursing team members care directed attending physician/app collaboration health care providers accordance philosophy policies promedica cancer institute, promedica physicians group, promedica outpatient medical oncology infusion centers. actively participates creation environment fosters patient, family, physician, employee satisfaction. ensures decisions made based patient family centered care philosophy utilizing evidenced based practices, focused safety, customer satisfaction, quality outcomes.scope service: registered nurse assesses provides nursing care individuals groups require specialized knowledge, judgment, skill derived principles biological, physical, behavioral, social, spiritual/cultural, nursing sciences. registered nurse functions within full scope nursing practice noted board nursing designated state practicing addition compliance hospitals accrediting bodies. education: current state license registered nurse skills: current basic cardiac life support america heart association license: current state license registered nursepreferred qualifications education: current state license bachelor prepared registered nurse years experience: preferred one year greater oncology experience certification: preferred ocn (oncology certified nurse) obtain set leadershipgeneral information/qualifications1. competencies, skills, training & abilities: complete maintain pci office practice oncology competencies annually ability respond effectively efficiently situations involving patients, personnel, visitors professional manner. demonstrates sound clinical skills judgment. ability critique daily practice error pursue corrective action. ability deal effectively changing environment open new ideas. functions dependable team member, assisting requested volunteering need obvious. able communicate effectively members health care team system demonstrates responsibility continued profession growth, competence, development. must able retrieve information computer.2. licensure/registration/certification/orientation: specialty certifications required complete pci oncology office rn coordinator nursing orientation. include: ons chemotherapy immunotherapy fundamental course pci core policies pci safe handling disposal chemotherapy waste learning modules assigned specific promedica cancer institute oncology nursing promedica 3. personal protective equipment (ppe): demonstrates knowledge use standard precautions ppe demonstrates knowledge use capr demonstrates knowledge use safe patient handling equipment4. physical demands: must able tolerate exposure dust, fumes, chemicals temperature changes, exposure blood borne pathogens bodily fluids. must able attain health requirements identified organization (i. e., ppd, respirator training, vaccines, appropriate). must able move hospital workstations, prolonged periods standing. ** must able frequently move, lift carry light heavy patients use safe patient handling equipment. must also able move medical equipment used care patient. must able life medium materials, non-material handling; continuous standing, walking, bending, stooping, reaching; frequent pushing, pulling, squatting occasional sitting, stairs, kneelingpromedica mission-based, not-for-profit integrated healthcare organization headquartered toledo, ohio. information, please visit qualified applicants receive consideration employment without regard race, color, national origin, ancestry, religion, sex/gender (including pregnancy), sexual orientation, gender identity gender expression, age, physical mental disability, military protected veteran status, citizenship, familial marital status, genetics, legally protected category. compliance americans disabilities act amendment act (adaaa), disability would like request accommodation order apply job promedica, please contact employment@equal opportunity employer/drug-free workplaceequal opportunity employerqualified applicants receive consideration employment without regard race, color, national origin, ancestry, religion, sex/gender (including pregnancy), sexual orientation, gender identity gender expression, age, physical mental disability, military protected veteran status, citizenship, familial marital status, genetics, legally protected category. compliance americans disabilities act amendment act (adaaa), disability would like request accommodation order apply job promedica senior care, please contact jobline@\n"
          ]
        }
      ],
      "source": [
        "# for verifying the result\n",
        "print(filtered_df.select('filtered_text').limit(10).collect()[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73JCvJ3illEr",
        "outputId": "7e0265df-22cf-4827-93a6-ff5756dc752f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "position summarythe registered nurse assesses patients, coordinates plan care, implements orders, evaluates nursing care provided oncology patients physician practice. nurse leads nursing team members care directed attending physician/app collaboration health care providers accordance philosophy policies promedica cancer institute, promedica physicians group, promedica outpatient medical oncology infusion centers. actively participates creation environment fosters patient, family, physician, employee satisfaction. ensures decisions made based patient family centered care philosophy utilizing evidenced based practices, focused safety, customer satisfaction, quality outcomes.scope service: registered nurse assesses provides nursing care individuals groups require specialized knowledge, judgment, skill derived principles biological, physical, behavioral, social, spiritual/cultural, nursing sciences. registered nurse functions within full scope nursing practice noted board nursing designated state practicing addition compliance hospitals accrediting bodies.job requirements: education: current state license registered nurse skills: current basic cardiac life support america heart association license: current state license registered nursepreferred qualifications education: current state license bachelor prepared registered nurse years experience: preferred one year greater oncology experience certification: preferred ocn (oncology certified nurse) obtain set leadershipgeneral information/qualifications1. competencies, skills, training & abilities: complete maintain pci office practice oncology competencies annually ability respond effectively efficiently situations involving patients, personnel, visitors professional manner. demonstrates sound clinical skills judgment. ability critique daily practice error pursue corrective action. ability deal effectively changing environment open new ideas. functions dependable team member, assisting requested volunteering need obvious. able communicate effectively members health care team system demonstrates responsibility continued profession growth, competence, development. must able retrieve information computer.2. licensure/registration/certification/orientation: specialty certifications required complete pci oncology office rn coordinator nursing orientation. include: ons chemotherapy immunotherapy fundamental course pci core policies pci safe handling disposal chemotherapy waste learning modules assigned specific promedica cancer institute oncology nursing promedica 3. personal protective equipment (ppe): demonstrates knowledge use standard precautions ppe demonstrates knowledge use capr demonstrates knowledge use safe patient handling equipment4. physical demands: must able tolerate exposure dust, fumes, chemicals temperature changes, exposure blood borne pathogens bodily fluids. must able attain health requirements identified organization (i. e., ppd, respirator training, vaccines, appropriate). must able move hospital workstations, prolonged periods standing. ** must able frequently move, lift carry light heavy patients use safe patient handling equipment. must also able move medical equipment used care patient. must able life medium materials, non-material handling; continuous standing, walking, bending, stooping, reaching; frequent pushing, pulling, squatting occasional sitting, stairs, kneelingpromedica mission-based, not-for-profit integrated healthcare organization headquartered toledo, ohio. information, please visit qualified applicants receive consideration employment without regard race, color, national origin, ancestry, religion, sex/gender (including pregnancy), sexual orientation, gender identity gender expression, age, physical mental disability, military protected veteran status, citizenship, familial marital status, genetics, legally protected category. compliance americans disabilities act amendment act (adaaa), disability would like request accommodation order apply job promedica, please contact employment@equal opportunity employer/drug-free workplace**requisition id:** 77733\n"
          ]
        }
      ],
      "source": [
        "print(filtered_df.select('filtered_text').collect()[31][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxByS6xe9Fwo"
      },
      "source": [
        "After checking the results with the actual data, we can say our algorithm is working well. The 2nd job description is about nursing and hospitals & 32nd is also for same as we can see above. This shows that our algorithm is doing a good job of finding similar job descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4ZaCEKQoLwb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
